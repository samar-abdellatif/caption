{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "caption.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1CBmUjWOczolI5egnqxFAyt1t6DgI12BI",
      "authorship_tag": "ABX9TyOqavz7nOCBO8GpVbwpcOxE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "645bb2812aaf4440a841d2be0f76b87f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_09a79661deda4f4c960c1b18cdabbb1c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ff11be456f694586972b3b3b83cc2787",
              "IPY_MODEL_adbf734ce0e34e7590c6b1c52733533c"
            ]
          }
        },
        "09a79661deda4f4c960c1b18cdabbb1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff11be456f694586972b3b3b83cc2787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_38dfa4c3754c475c86aaf67b17e4145c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cebeba77e9e043a9a2bd6b6a358bcffe"
          }
        },
        "adbf734ce0e34e7590c6b1c52733533c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7d509c202b524968ae3d21cb764479d5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/? [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ce49b3425ca246b982971573ea2aa893"
          }
        },
        "38dfa4c3754c475c86aaf67b17e4145c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cebeba77e9e043a9a2bd6b6a358bcffe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d509c202b524968ae3d21cb764479d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ce49b3425ca246b982971573ea2aa893": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "38fdb1c1570448ba976bbb5e4113afce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cb2bc7d81c8c47978ee287dcd07725f2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a5f062c61a6c46399350fbaaa33284e3",
              "IPY_MODEL_aaf62bdbd76c4a47a5dc414e3ae762fd"
            ]
          }
        },
        "cb2bc7d81c8c47978ee287dcd07725f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5f062c61a6c46399350fbaaa33284e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8cdf53589a904028ac2a055a33edacf0",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 8100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 8100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_857287fb8ab7490da1243bd974df33e0"
          }
        },
        "aaf62bdbd76c4a47a5dc414e3ae762fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4d582a95f1a644998e3b6a50871ac24b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8100/8100 [2:36:34&lt;00:00,  1.16s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a826bc6ed76414287fd91fdfaa7decd"
          }
        },
        "8cdf53589a904028ac2a055a33edacf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "857287fb8ab7490da1243bd974df33e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d582a95f1a644998e3b6a50871ac24b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a826bc6ed76414287fd91fdfaa7decd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samar-abdellatif/caption/blob/master/caption.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlZC94lfiwok",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "outputId": "f78d349a-6e3f-4bab-d940-a3b5fe3b8c51"
      },
      "source": [
        "pip install tensorflow==1.14"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 38kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 45.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.9.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.18.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 34.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.27.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.34.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14) (46.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
            "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
            "  Found existing installation: tensorboard 2.2.0\n",
            "    Uninstalling tensorboard-2.2.0:\n",
            "      Successfully uninstalled tensorboard-2.2.0\n",
            "  Found existing installation: tensorflow 2.2.0rc2\n",
            "    Uninstalling tensorflow-2.2.0rc2:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc2\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YTHvu7Li_Qx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f68aea96-05a7-4485-e8fd-e0bfbdb3eb31"
      },
      "source": [
        "pip install keras pillow tqdm jupyterlab numpy"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.38.0)\n",
            "Collecting jupyterlab\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/d6/9e6a8a04f4fc337fbc05065d1ba4ba3460a09ee41355410bcd6d8be8841a/jupyterlab-2.0.1-py3-none-any.whl (7.7MB)\n",
            "\u001b[K     |████████████████████████████████| 7.7MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Collecting jupyterlab-server~=1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/3c/ea/ae83699c4217d5668f62402445bbe4da11cc63898fbe7a57d8fed6281a04/jupyterlab_server-1.0.7-py3-none-any.whl\n",
            "Requirement already satisfied: notebook>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from jupyterlab) (5.2.2)\n",
            "Requirement already satisfied: jinja2>=2.10 in /usr/local/lib/python3.6/dist-packages (from jupyterlab) (2.11.1)\n",
            "Requirement already satisfied: tornado!=6.0.0,!=6.0.1,!=6.0.2 in /usr/local/lib/python3.6/dist-packages (from jupyterlab) (4.5.3)\n",
            "Collecting json5\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/4b/c0b4c7e238a98165a0281d6ad52ee4a8401318580d2fc9d3844dda2ef5f7/json5-0.9.4-py2.py3-none-any.whl\n",
            "Collecting jsonschema>=3.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/8f/51e89ce52a085483359217bc72cdbf6e75ee595d5b1d4b5ade40c7e018b8/jsonschema-3.2.0-py2.py3-none-any.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (4.6.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (0.2.0)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (0.8.3)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (4.3.3)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (5.3.4)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (5.0.5)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (5.6.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (4.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.10->jupyterlab) (1.1.1)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=1.0.0->jupyterlab) (0.16.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=1.0.0->jupyterlab) (19.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=1.0.0->jupyterlab) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=1.0.0->jupyterlab) (46.0.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook>=4.3.1->jupyterlab) (0.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2.1->notebook>=4.3.1->jupyterlab) (4.4.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->notebook>=4.3.1->jupyterlab) (17.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->notebook>=4.3.1->jupyterlab) (2.8.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (0.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (3.1.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (0.6.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (2.1.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (0.4.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (1.4.2)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->notebook>=4.3.1->jupyterlab) (5.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->jupyterlab-server~=1.0.0->jupyterlab) (3.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.3.1->jupyterlab) (0.5.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (0.7.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (0.1.9)\n",
            "Installing collected packages: json5, jsonschema, jupyterlab-server, jupyterlab\n",
            "  Found existing installation: jsonschema 2.6.0\n",
            "    Uninstalling jsonschema-2.6.0:\n",
            "      Successfully uninstalled jsonschema-2.6.0\n",
            "Successfully installed json5-0.9.4 jsonschema-3.2.0 jupyterlab-2.0.1 jupyterlab-server-1.0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjJLonf3jE4K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48,
          "referenced_widgets": [
            "645bb2812aaf4440a841d2be0f76b87f",
            "09a79661deda4f4c960c1b18cdabbb1c",
            "ff11be456f694586972b3b3b83cc2787",
            "adbf734ce0e34e7590c6b1c52733533c",
            "38dfa4c3754c475c86aaf67b17e4145c",
            "cebeba77e9e043a9a2bd6b6a358bcffe",
            "7d509c202b524968ae3d21cb764479d5",
            "ce49b3425ca246b982971573ea2aa893"
          ]
        },
        "outputId": "f2d0431c-a0ba-4911-9a90-08bb44eeb19a"
      },
      "source": [
        "import string\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "from pickle import dump, load\n",
        "import numpy as np\n",
        "import sys\n",
        "import io\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.applications.xception import Xception, preprocess_input\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.merge import add\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dense, LSTM, Embedding, Dropout\n",
        "# small library for seeing the progress of loops.\n",
        "from tqdm.notebook import tqdm\n",
        "tqdm().pandas()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "645bb2812aaf4440a841d2be0f76b87f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWLnLkdTjQT8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d7343300-bbe6-4575-8fd9-5aeacb910078"
      },
      "source": [
        "# Loading a text file into memory\n",
        "def load_doc(filename):\n",
        "    # Opening the file as read only\n",
        "    file = open(filename, 'r')\n",
        "    text = file.read()\n",
        "    file.close()\n",
        "    return text\n",
        "# get all imgs with their captions\n",
        "def all_img_captions(filename):\n",
        "    file = load_doc(filename)\n",
        "    captions = file.split('\\n')\n",
        "    descriptions ={}\n",
        "    for caption in captions[:-1]:\n",
        "        img, caption = caption.split('\\t')\n",
        "        if img[:-2]   not in descriptions:\n",
        "            descriptions[img[:-2]] = list()\n",
        "            \n",
        "        else:\n",
        "            descriptions[img[:-2]].append(caption)\n",
        "    return descriptions\n",
        "#Data cleaning- lower casing, removing puntuations and words containing numbers\n",
        "def cleaning_text(captions):\n",
        "    table = str.maketrans('','',string.punctuation)\n",
        "    for img,caps in captions.items():\n",
        "        for i,img_caption in enumerate(caps):\n",
        "            img_caption.replace(\"-\",\" \")\n",
        "            desc = img_caption.split()\n",
        "            #converts to lowercase\n",
        "            desc = [word.lower() for word in desc]\n",
        "            #remove punctuation from each token\n",
        "            desc = [word.translate(table) for word in desc]\n",
        "            #remove hanging 's and a \n",
        "            desc = [word for word in desc if(len(word)>1)]\n",
        "            #remove tokens with numbers in them\n",
        "            desc = [word for word in desc if(word.isalpha())]\n",
        "            #convert back to string\n",
        "            img_caption = ' '.join(desc)\n",
        "            captions[img][i]= img_caption\n",
        "    return captions\n",
        "def text_vocabulary(descriptions):\n",
        "    # build vocabulary of all unique words\n",
        "    vocab = set()\n",
        "    for key in descriptions.keys():\n",
        "        [vocab.update(d.split()) for d in descriptions[key]]\n",
        "    return vocab\n",
        "#All descriptions in one file \n",
        "def save_descriptions(descriptions, filename):\n",
        "    lines = list()\n",
        "    for key, desc_list in descriptions.items():\n",
        "        for desc in desc_list:\n",
        "            lines.append(key + '\\t' + desc )\n",
        "    data = \"\\n\".join(lines)\n",
        "    file = open(filename,\"w\")\n",
        "    file.write(data)\n",
        "    file.close()\n",
        "# Set these path according to project folder in you system\n",
        "dataset_text = \"/content/drive/My Drive/python-project-image-caption-generator/Flickr8k_text\"\n",
        "dataset_images = \"/content/drive/My Drive/python-project-image-caption-generator/Flickr8k_Dataset/Flicker8k_Dataset\"\n",
        "#we prepare our text data\n",
        "filename = dataset_text + \"/\" + \"Flickr8k.token.txt\"\n",
        "#loading the file that contains all data\n",
        "#mapping them into descriptions dictionary img to 5 captions\n",
        "descriptions = all_img_captions(filename)\n",
        "print(\"Length of descriptions =\" ,len(descriptions))\n",
        "#cleaning the descriptions\n",
        "clean_descriptions = cleaning_text(descriptions)\n",
        "#building vocabulary \n",
        "vocabulary = text_vocabulary(clean_descriptions)\n",
        "print(\"Length of vocabulary = \", len(vocabulary))\n",
        "#saving each description to file \n",
        "save_descriptions(clean_descriptions, \"descriptions.txt\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of descriptions = 8092\n",
            "Length of vocabulary =  7951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgc65B2yjduO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_features(directory):\n",
        "        model = Xception( include_top=False, pooling='avg' )\n",
        "        features = {}\n",
        "        for img in tqdm(os.listdir(directory)):\n",
        "            filename = directory + \"/\" + img\n",
        "            image = Image.open(filename)\n",
        "            image = image.resize((299,299))\n",
        "            image = np.expand_dims(image, axis=0)\n",
        "            #image = preprocess_input(image)\n",
        "            image = image/127.5\n",
        "            image = image - 1.0\n",
        "            feature = model.predict(image)\n",
        "            features[img] = feature\n",
        "        return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S838kEKjjHA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371,
          "referenced_widgets": [
            "38fdb1c1570448ba976bbb5e4113afce",
            "cb2bc7d81c8c47978ee287dcd07725f2",
            "a5f062c61a6c46399350fbaaa33284e3",
            "aaf62bdbd76c4a47a5dc414e3ae762fd",
            "8cdf53589a904028ac2a055a33edacf0",
            "857287fb8ab7490da1243bd974df33e0",
            "4d582a95f1a644998e3b6a50871ac24b",
            "5a826bc6ed76414287fd91fdfaa7decd"
          ]
        },
        "outputId": "570165c1-e15e-43bc-b0a6-48d7c5ff969e"
      },
      "source": [
        "features = extract_features(dataset_images)\n",
        "dump(features, open(\"features.p\",\"wb\"))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38fdb1c1570448ba976bbb5e4113afce",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=8100), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKlGWGuEGQqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = load(open(\"features.p\",\"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afgdNbNvGahJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the data \n",
        "def load_photos(filename):\n",
        "    file = load_doc(filename)\n",
        "    photos = file.split(\"\\n\")[:-1]\n",
        "    return photos\n",
        "def load_clean_descriptions(filename, photos): \n",
        "    #loading clean_descriptions\n",
        "    file = load_doc(filename)\n",
        "    descriptions = {}\n",
        "    for line in file.split(\"\\n\"):\n",
        "        words = line.split()\n",
        "        if len(words)<1 :\n",
        "            continue\n",
        "        image, image_caption = words[0], words[1:]\n",
        "        if image in photos:\n",
        "            if image not in descriptions:\n",
        "                descriptions[image] = []\n",
        "            desc = '<start> ' + \" \".join(image_caption) + ' <end>'\n",
        "            descriptions[image].append(desc)\n",
        "    return descriptions\n",
        "def load_features(photos):\n",
        "    #loading all features\n",
        "    all_features = load(open(\"features.p\",\"rb\"))\n",
        "    #selecting only needed features\n",
        "    features = {k:all_features[k] for k in photos}\n",
        "    return features\n",
        "filename = dataset_text + \"/\" + \"Flickr_8k.trainImages.txt\"\n",
        "#train = loading_data(filename)\n",
        "train_imgs = load_photos(filename)\n",
        "train_descriptions = load_clean_descriptions(\"descriptions.txt\", train_imgs)\n",
        "train_features = load_features(train_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BRuyWLAGh-i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "155d231d-9943-452c-8cbf-96d0542191a3"
      },
      "source": [
        "#converting dictionary to clean list of descriptions\n",
        "def dict_to_list(descriptions):\n",
        "    all_desc = []\n",
        "    for key in descriptions.keys():\n",
        "        [all_desc.append(d) for d in descriptions[key]]\n",
        "    return all_desc\n",
        "#creating tokenizer class \n",
        "#this will vectorise text corpus\n",
        "#each integer will represent token in dictionary\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "def create_tokenizer(descriptions):\n",
        "    desc_list = dict_to_list(descriptions)\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(desc_list)\n",
        "    return tokenizer\n",
        "# give each word an index, and store that into tokenizer.p pickle file\n",
        "tokenizer = create_tokenizer(train_descriptions)\n",
        "dump(tokenizer, open('tokenizer.p', 'wb'))\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "vocab_size"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6889"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w_nVyHWGpSS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d26cb7c4-3c85-413d-ae03-402bcc9841a5"
      },
      "source": [
        "#calculate maximum length of descriptions\n",
        "def max_length(descriptions):\n",
        "    desc_list = dict_to_list(descriptions)\n",
        "    return max(len(d.split()) for d in desc_list)\n",
        "    \n",
        "max_length = max_length(descriptions)\n",
        "max_length"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCp-UG0bGt3n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c25bfa82-5d76-4172-bf18-640cdbae60dc"
      },
      "source": [
        "#create input-output sequence pairs from the image description.\n",
        "#data generator, used by model.fit_generator()\n",
        "def data_generator(descriptions, features, tokenizer, max_length):\n",
        "    while 1:\n",
        "        for key, description_list in descriptions.items():\n",
        "            #retrieve photo features\n",
        "            feature = features[key][0]\n",
        "            input_image, input_sequence, output_word = create_sequences(tokenizer, max_length, description_list, feature)\n",
        "            yield [[input_image, input_sequence], output_word]\n",
        "def create_sequences(tokenizer, max_length, desc_list, feature):\n",
        "    X1, X2, y = list(), list(), list()\n",
        "    # walk through each description for the image\n",
        "    for desc in desc_list:\n",
        "        # encode the sequence\n",
        "        seq = tokenizer.texts_to_sequences([desc])[0]\n",
        "        # split one sequence into multiple X,y pairs\n",
        "        for i in range(1, len(seq)):\n",
        "            # split into input and output pair\n",
        "            in_seq, out_seq = seq[:i], seq[i]\n",
        "            # pad input sequence\n",
        "            in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "            # encode output sequence\n",
        "            out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "            # store\n",
        "            X1.append(feature)\n",
        "            X2.append(in_seq)\n",
        "            y.append(out_seq)\n",
        "    return np.array(X1), np.array(X2), np.array(y)\n",
        "#You can check the shape of the input and output for your model\n",
        "[a,b],c = next(data_generator(train_descriptions, features, tokenizer, max_length))\n",
        "a.shape, b.shape, c.shape\n",
        "#((47, 2048), (47, 32), (47, 7577))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((32, 2048), (32, 32), (32, 6889))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pP5ShxjG2gb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import plot_model\n",
        "# define the captioning model\n",
        "def define_model(vocab_size, max_length):\n",
        "    # features from the CNN model squeezed from 2048 to 256 nodes\n",
        "    inputs1 = Input(shape=(2048,))\n",
        "    fe1 = Dropout(0.5)(inputs1)\n",
        "    fe2 = Dense(256, activation='relu')(fe1)\n",
        "    # LSTM sequence model\n",
        "    inputs2 = Input(shape=(max_length,))\n",
        "    se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
        "    se2 = Dropout(0.5)(se1)\n",
        "    se3 = LSTM(256)(se2)\n",
        "    # Merging both models\n",
        "    decoder1 = add([fe2, se3])\n",
        "    decoder2 = Dense(256, activation='relu')(decoder1)\n",
        "    outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
        "    # tie it together [image, seq] [word]\n",
        "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "    # summarize model\n",
        "    print(model.summary())\n",
        "    plot_model(model, to_file='model.png', show_shapes=True)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyqAumWCVjq8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "08049205-d109-4e7f-87cb-cae09868968d"
      },
      "source": [
        "# train our model\n",
        "print('Dataset: ', len(train_imgs))\n",
        "print('Descriptions: train=', len(train_descriptions))\n",
        "print('Photos: train=', len(train_features))\n",
        "print('Vocabulary Size:', vocab_size)\n",
        "print('Description Length: ', max_length)\n",
        "model = define_model(vocab_size, max_length)\n",
        "epochs = 10\n",
        "steps = len(train_descriptions)\n",
        "# making a directory models to save our models\n",
        "os.mkdir(\"models\")\n",
        "for i in range(epochs):\n",
        "    generator = data_generator(train_descriptions, train_features, tokenizer, max_length)\n",
        "    model.fit_generator(generator, epochs=1, steps_per_epoch= steps, verbose=1)\n",
        "    model.save(\"models/model_\" + str(i) + \".h5\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset:  6000\n",
            "Descriptions: train= 6000\n",
            "Photos: train= 6000\n",
            "Vocabulary Size: 6889\n",
            "Description Length:  32\n",
            "ERROR! Session/line number was not unique in database. History logging moved to new session 63\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3239: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 32)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 2048)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 32, 256)      1763584     input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 2048)         0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 32, 256)      0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          524544      dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 256)          525312      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 256)          0           dense_1[0][0]                    \n",
            "                                                                 lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 256)          65792       add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 6889)         1770473     dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 4,649,705\n",
            "Trainable params: 4,649,705\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 2007s 334ms/step - loss: 4.5659\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 1915s 319ms/step - loss: 3.7430\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 1889s 315ms/step - loss: 3.4579\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 1880s 313ms/step - loss: 3.2917\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 1885s 314ms/step - loss: 3.1718\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 1885s 314ms/step - loss: 3.0836\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 1900s 317ms/step - loss: 3.0197\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 1874s 312ms/step - loss: 2.9623\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 1854s 309ms/step - loss: 2.9287\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 1827s 304ms/step - loss: 2.8931\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYgB8rglhhBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image \n",
        "import matplotlib.pyplot as plt\n",
        "import argparse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "22be6cdc-e1a5-4c23-8930-4e17d681c821",
        "id": "8lPv_LudyoFo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument('-i','--image', required=False, help=\"Image Path\", default=\"content/drive/My Drive/python-project-image-caption-generator/Flicker8k_Dataset/Flicker8k_Dataset/111537222_07e56d5a30.jpg\")\n",
        "args = vars(ap.parse_args())\n",
        "img_path = args['image']"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] [-i IMAGE]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-9a10aa5f-fc86-444c-b6cf-c00e9d8f89f3.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLkyu8xzG8Yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_features(filename, model):\n",
        "        try:\n",
        "            image = Image.open(filename)\n",
        "        except:\n",
        "            print(\"ERROR: Couldn't open image! Make sure the image path and extension is correct\")\n",
        "        image = image.resize((299,299))\n",
        "        image = np.array(image)\n",
        "        # for images that has 4 channels, we convert them into 3 channels\n",
        "        if image.shape[2] == 4: \n",
        "            image = image[..., :3]\n",
        "        image = np.expand_dims(image, axis=0)\n",
        "        image = image/127.5\n",
        "        image = image - 1.0\n",
        "        feature = model.predict(image)\n",
        "        return feature\n",
        "def word_for_id(integer, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if index == integer:\n",
        "         return word\n",
        "    return None\n",
        "def generate_desc(model, tokenizer, photo, max_length):\n",
        "    in_text = 'start'\n",
        "    for i in range(max_length):\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        pred = model.predict([photo,sequence], verbose=0)\n",
        "        pred = np.argmax(pred)\n",
        "        word = word_for_id(pred, tokenizer)\n",
        "        if word is None:\n",
        "            break\n",
        "        in_text += ' ' + word\n",
        "        if word == 'end':\n",
        "            break\n",
        "    return in_text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScdCYPAPgSqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#path = 'Flicker8k_Dataset/111537222_07e56d5a30.jpg'\n",
        "max_length = 32\n",
        "tokenizer = load(open(\"tokenizer.p\",\"rb\"))\n",
        "model = load_model('models/model_9.h5')\n",
        "xception_model = Xception(include_top=False, pooling=\"avg\")\n",
        "photo = extract_features(img_path, xception_model)\n",
        "img = Image.open(img_path)\n",
        "description = generate_desc(model, tokenizer, photo, max_length)\n",
        "print(\"\\n\\n\")\n",
        "print(description)\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}